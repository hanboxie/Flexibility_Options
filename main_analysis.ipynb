{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyomo.environ as pyo\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models and Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Load YAML config\n",
    "with open(\"config/model_config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Unpack general\n",
    "general_cfg = config[\"general\"]\n",
    "num_periods = general_cfg[\"num_periods\"]\n",
    "num_scenarios = general_cfg[\"num_scenarios\"]\n",
    "num_generators = general_cfg[\"num_generators\"]\n",
    "num_tiers = general_cfg[\"num_tiers\"]\n",
    "num_storage = general_cfg[\"num_storage\"]\n",
    "\n",
    "# Unpack paths\n",
    "paths = config[\"data_paths\"]\n",
    "gen_csv_path = paths[\"generator_csv\"]\n",
    "storage_csv_path = paths[\"storage_csv\"]\n",
    "demand_csv_path = paths[\"demand_csv\"]\n",
    "\n",
    "# Unpack solver config\n",
    "solver_cfg = config[\"solver\"]\n",
    "solver_name = solver_cfg[\"name\"]\n",
    "solver_exec = solver_cfg.get(\"executable\")\n",
    "solver_options = solver_cfg.get(\"options\", {})\n",
    "\n",
    "import sys\n",
    "sys.path.append('./src')\n",
    "\n",
    "from DAFOModel import DAFOModel\n",
    "from RTSimModel import RTSimModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SystemDataProcessor:\n",
    "    def __init__(self, gen_csv_path, storage_csv_path, demand_csv_path):\n",
    "        self.gen_csv_path = gen_csv_path\n",
    "        self.storage_csv_path = storage_csv_path\n",
    "        self.demand_csv_path = demand_csv_path\n",
    "        self.gen_data = None\n",
    "        self.storage_data = None\n",
    "        self.demand_data = None\n",
    "\n",
    "    def load_data(self):\n",
    "        try:\n",
    "            self.gen_data = pd.read_csv(self.gen_csv_path).head(5)\n",
    "            self.storage_data = pd.read_csv(self.storage_csv_path).head(1)\n",
    "            print(f\"Generator and Storage data loaded successfully. {len(self.gen_data)} generators and {len(self.storage_data)} storages found.\")\n",
    "            self.demand_data = pd.read_csv(self.demand_csv_path)\n",
    "            print(f\"Demand data loaded successfully. {len(self.demand_data)} periods found.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def process_gen_data(self):\n",
    "        id_col = 'GEN UID'\n",
    "        column_mapping = {\n",
    "            # 'Ramp Rate MW/Min': '', \n",
    "            # 'Fuel Price $/MMBTU': '', \n",
    "            # 'VOM': '',\n",
    "            'PMax MW': 'CAP',\n",
    "            'Ramp Rate MW/Min': 'RR',\n",
    "        }\n",
    "\n",
    "        relevant_cols = list(column_mapping.keys())\n",
    "        existing_cols = [col for col in relevant_cols if col in self.gen_data.columns]\n",
    "        selected_cols = [id_col] + existing_cols\n",
    "        gen_data_filtered = self.gen_data[selected_cols].copy()\n",
    "\n",
    "        rename_dict = {col: column_mapping[col] for col in column_mapping if col in gen_data_filtered.columns}\n",
    "        gen_data_filtered.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "        original_ids = gen_data_filtered[id_col].tolist()\n",
    "        gen_id_mapping = {original_id: i+1 for i, original_id in enumerate(original_ids)}\n",
    "        gen_data_filtered[id_col] = gen_data_filtered[id_col].map(gen_id_mapping)\n",
    "        \n",
    "        gen_data_filtered.set_index(id_col, inplace=True)\n",
    "\n",
    "        # if 'Fuel Price $/MMBTU' in gen_data_filtered.columns and 'HR_avg_0' in self.gen_data.columns:\n",
    "        #     gen_data_filtered['VC'] = self.gen_data['Fuel Price $/MMBTU'] * self.gen_data['HR_avg_0'] / 1000.0\n",
    "        #     if 'VOM' in gen_data_filtered.columns:\n",
    "        #         gen_data_filtered['VC'] += gen_data_filtered['VOM']\n",
    "        \n",
    "        # TODO - CALCULATE VC, VCUP, VCDN\n",
    "        gen_data_filtered['VC'] = 20\n",
    "        gen_data_filtered['VCUP'] = 20\n",
    "        gen_data_filtered['VCDN'] = 20\n",
    "\n",
    "        params = ['CAP', 'RR','VC','VCUP','VCDN']\n",
    "        gen_data_dict = {}\n",
    "\n",
    "        for param in params:\n",
    "            if param in gen_data_filtered.columns:\n",
    "                param_dict = {}\n",
    "                for gen_idx in gen_data_filtered.index:\n",
    "                    param_dict[gen_idx] = gen_data_filtered.loc[gen_idx, param]\n",
    "                gen_data_dict[param] = param_dict\n",
    "            \n",
    "        return gen_data_dict\n",
    "\n",
    "    def process_storage_data(self):\n",
    "        if self.storage_data is None or self.storage_data.empty:\n",
    "            return {}\n",
    "            \n",
    "        try:\n",
    "            id_col = 'GEN UID'\n",
    "\n",
    "            column_mapping = {\n",
    "                'Max Volume GWh': 'E_MAX',\n",
    "                'Rating MVA': 'P_MAX',\n",
    "                'Initial Volume GWh': 'E0',\n",
    "                # 'Storage Roundtrip Efficiency': 'ETA'\n",
    "            }\n",
    "\n",
    "            relevant_cols = list(column_mapping.keys())\n",
    "            existing_cols = [col for col in relevant_cols if col in self.storage_data.columns]\n",
    "                \n",
    "            selected_cols = [id_col] + existing_cols\n",
    "            storage_data_filtered = self.storage_data[selected_cols].copy()\n",
    "\n",
    "            rename_dict = {col: column_mapping[col] for col in column_mapping if col in storage_data_filtered.columns}\n",
    "            storage_data_filtered.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "            original_ids = storage_data_filtered[id_col].tolist()\n",
    "            storage_id_mapping = {original_id: i+1 for i, original_id in enumerate(original_ids)}\n",
    "            storage_data_filtered[id_col] = storage_data_filtered[id_col].map(storage_id_mapping)\n",
    "        \n",
    "            storage_data_filtered.set_index(id_col, inplace=True)\n",
    "\n",
    "            storage_data_dict = {}\n",
    "\n",
    "            if 'E_MAX' in storage_data_filtered.columns:\n",
    "                storage_data_dict['E_MAX'] = {\n",
    "                    ## REMINDER: REMOVE THIS, just for testing\n",
    "                    # storage_idx: float(storage_data_filtered.at[storage_idx, 'E_MAX'])\n",
    "                    storage_idx: 0\n",
    "                    for storage_idx in storage_data_filtered.index\n",
    "                }\n",
    "                \n",
    "            if 'P_MAX' in storage_data_filtered.columns:\n",
    "                storage_data_dict['P_MAX'] = {\n",
    "                    storage_idx: float(storage_data_filtered.loc[storage_idx, 'P_MAX'])\n",
    "                    for storage_idx in storage_data_filtered.index\n",
    "                }\n",
    "            \n",
    "            # check charging and discharging efficiency\n",
    "            storage_data_dict['ETA_CH'] = {\n",
    "                storage_idx: 0.9    \n",
    "                for storage_idx in storage_data_filtered.index\n",
    "            }\n",
    "            storage_data_dict['ETA_DCH'] = {\n",
    "                storage_idx: 0.9\n",
    "                for storage_idx in storage_data_filtered.index\n",
    "            }\n",
    "            storage_data_dict['STORAGE_COST'] = {\n",
    "                storage_idx: 0.9\n",
    "                for storage_idx in storage_data_filtered.index\n",
    "            }\n",
    "            storage_data_dict['E0'] = {\n",
    "                storage_idx: 0.0\n",
    "                for storage_idx in storage_data_filtered.index\n",
    "            }\n",
    "            storage_data_dict['E_FINAL'] = {\n",
    "                storage_idx: 0.0\n",
    "                for storage_idx in storage_data_filtered.index\n",
    "            }\n",
    "\n",
    "            return storage_data_dict\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing storage data: {str(e)}\")\n",
    "            return {}\n",
    "    \n",
    "    def process_demand_data(self, num_periods=24):\n",
    "        try:\n",
    "            demand_data = self.demand_data.head(num_periods)\n",
    "            demand_dict = demand_data.set_index(demand_data.index + 1)['1'].to_dict()\n",
    "            return demand_dict\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing demand data: {str(e)}\")\n",
    "            return {}     \n",
    "\n",
    "    def prepare_pyomo_data(self, num_periods, num_scenarios, num_tiers):\n",
    "        \"\"\"Prepare the data for the Pyomo model.\"\"\"\n",
    "        if self.gen_data is None:\n",
    "            success = self.load_data()\n",
    "            if not success:\n",
    "                return None\n",
    "                \n",
    "        gen_data_dict = self.process_gen_data()\n",
    "        storage_data_dict = self.process_storage_data()\n",
    "        demand_data_dict = self.process_demand_data(num_periods)\n",
    "        \n",
    "        num_generators = len(gen_data_dict.get('CAP', {}))\n",
    "        num_storage = len(storage_data_dict.get('E_MAX', {}))\n",
    "        \n",
    "        sets = {\n",
    "            'T': {None: list(range(1, num_periods + 1))},\n",
    "            'S': {None: list(range(1, num_scenarios + 1))},\n",
    "            'G': {None: list(range(1, num_generators + 1))},\n",
    "            'R': {None: list(range(1, num_tiers + 1))},\n",
    "            'B': {None: list(range(1, num_storage + 1))}\n",
    "        }\n",
    "        \n",
    "        reda_data = {} # dont need REDA for DA\n",
    "        RE_data = np.random.uniform(0, 100, size=(num_scenarios, num_periods))\n",
    "        RE_dict = {(s, t): RE_data[s-1][t-1] for s in range(1, num_scenarios+1) for t in range(1, num_periods+1)}\n",
    "        \n",
    "        fo_params = {\n",
    "            # Manual values\n",
    "            'D1': {None: 5},\n",
    "            'D2': {None: 550.0},\n",
    "            'PEN': {None: 2000},\n",
    "            'PENDN': {None: 0},\n",
    "            'smallM': {None: 0.01},\n",
    "            # check probabilities\n",
    "            'probTU': {1: 0.2, 2: 0.4, 3: 0.6, 4: 0.8},\n",
    "            'probTD': {1: 0.8, 2: 0.6, 3: 0.4, 4: 0.2}\n",
    "        }\n",
    "        \n",
    "        pyomo_data = {}\n",
    "        pyomo_data.update(sets)\n",
    "        # pyomo_data.update(gen_data_dict)\n",
    "        pyomo_data.update(storage_data_dict)\n",
    "        pyomo_data.update(fo_params)\n",
    "        pyomo_data['DEMAND'] = demand_data_dict\n",
    "        \n",
    "        # TODO - CALCULATE REDA, RE\n",
    "        pyomo_data['CAP'] = {1: 50, 2: 10, 3: 10, 4: 10, 5: 10}\n",
    "        pyomo_data['RR'] = {1: 50, 2: 10, 3: 10, 4: 10, 5: 10}\n",
    "        pyomo_data['VC'] = {1: 20, 2: 35, 3: 50, 4: 60, 5: 70}\n",
    "        pyomo_data['VCUP'] = {1: 20, 2: 35, 3: 50, 4: 60, 5: 70}\n",
    "        pyomo_data['VCDN'] = {1: 20, 2: 35, 3: 50, 4: 60, 5: 70}\n",
    "        pyomo_data['RE'] = {\n",
    "            (1, 1): 131, (1, 2): 131,\n",
    "            (2, 1): 141, (2, 2): 141,\n",
    "            (3, 1): 155, (3, 2): 155,\n",
    "            (4, 1): 165, (4, 2): 165,\n",
    "            (5, 1): 172, (5, 2): 172\n",
    "        }\n",
    "        # pyomo_data['RE'] = {\n",
    "        #     (1, 1): 131, (1, 2): 131,\n",
    "        # }\n",
    "        pyomo_data['DEMAND'] = {1: 200, 2:200}\n",
    "        pyomo_data['REDA'] = reda_data\n",
    "        # pyomo_data['RE'] = RE_dict\n",
    "\n",
    "        pyomo_data = {None: pyomo_data} # reformat for pyomo\n",
    "\n",
    "        # TODO: UPDATE REQUIRED PARAMETERS\n",
    "        required_params = [\n",
    "            'CAP', 'VC', 'VCUP', 'VCDN', 'RR',\n",
    "            'E_MAX', 'P_MAX', 'ETA_CH', 'ETA_DCH', 'E0', 'E_FINAL', 'STORAGE_COST',\n",
    "            'D1', 'D2', 'PEN', 'PENDN', 'smallM', 'probTU', 'probTD',\n",
    "            'DEMAND', 'REDA', 'RE'\n",
    "        ]\n",
    "        \n",
    "        missing_params = [param for param in required_params if param not in pyomo_data[None]]\n",
    "        if missing_params:\n",
    "            print(f\"Warning: Missing parameters: {missing_params}\")\n",
    "        \n",
    "        print(storage_data_dict)\n",
    "        return pyomo_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator and Storage data loaded successfully. 5 generators and 1 storages found.\n",
      "Demand data loaded successfully. 8784 periods found.\n",
      "{'E_MAX': {1: 0}, 'P_MAX': {1: 200.0}, 'ETA_CH': {1: 0.9}, 'ETA_DCH': {1: 0.9}, 'STORAGE_COST': {1: 0.9}, 'E0': {1: 0.0}, 'E_FINAL': {1: 0.0}}\n",
      "\n",
      "Welcome to IBM(R) ILOG(R) CPLEX(R) Interactive Optimizer 22.1.2.0\n",
      "  with Simplex, Mixed Integer & Barrier Optimizers\n",
      "5725-A06 5725-A29 5724-Y48 5724-Y49 5724-Y54 5724-Y55 5655-Y21\n",
      "Copyright IBM Corp. 1988, 2024.  All Rights Reserved.\n",
      "\n",
      "Type 'help' for a list of available commands.\n",
      "Type 'help' followed by a command name for more\n",
      "information on commands.\n",
      "\n",
      "CPLEX> Logfile 'cplex.log' closed.\n",
      "Logfile 'C:\\Users\\hanbo\\AppData\\Local\\Temp\\tmpnnsz1ud4.cplex.log' open.\n",
      "CPLEX> Problem 'C:\\Users\\hanbo\\AppData\\Local\\Temp\\tmpgsgaguou.pyomo.lp' read.\n",
      "Read time = 0.00 sec. (0.02 ticks)\n",
      "CPLEX> Problem name         : C:\\Users\\hanbo\\AppData\\Local\\Temp\\tmpgsgaguou.pyomo.lp\n",
      "Objective sense      : Minimize\n",
      "Variables            :     168  [Nneg: 158,  Free: 10,  Qobj: 12]\n",
      "Objective nonzeros   :     140\n",
      "Objective Q nonzeros :      32\n",
      "Linear constraints   :     138  [Less: 108,  Equal: 30]\n",
      "  Nonzeros           :     605\n",
      "  RHS nonzeros       :      98\n",
      "\n",
      "Variables            : Min LB: 0.000000         Max UB: all infinite   \n",
      "Objective nonzeros   : Min   : 0.01000000       Max   : 1600.000       \n",
      "Objective Q nonzeros : Min   : 220.0000         Max   : 1100.000       \n",
      "Linear constraints   :\n",
      "  Nonzeros           : Min   : 0.9000000        Max   : 1.111111       \n",
      "  RHS nonzeros       : Min   : 10.00000         Max   : 200.0000       \n",
      "CPLEX> Version identifier: 22.1.2.0 | 2024-11-25 | 0edbb82fd\n",
      "Number of nonzeros in lower triangle of Q = 10\n",
      "Using Approximate Minimum Degree ordering\n",
      "Total time for automatic ordering = 0.00 sec. (0.00 ticks)\n",
      "Summary statistics for factor of Q:\n",
      "  Rows in Factor            = 12\n",
      "  Integer space required    = 12\n",
      "  Total non-zeros in factor = 42\n",
      "  Total FP ops to factor    = 182\n",
      "Tried aggregator 1 time.\n",
      "QP Presolve eliminated 22 rows and 4 columns.\n",
      "QP Presolve added 0 rows and 12 columns.\n",
      "Aggregator did 16 substitutions.\n",
      "Reduced QP has 112 rows, 160 columns, and 596 nonzeros.\n",
      "Reduced QP objective Q matrix has 10 nonzeros.\n",
      "Presolve time = 0.00 sec. (0.13 ticks)\n",
      "Parallel mode: using up to 32 threads for barrier.\n",
      "Number of nonzeros in lower triangle of A*A' = 731\n",
      "Using Approximate Minimum Degree ordering\n",
      "Total time for automatic ordering = 0.00 sec. (0.05 ticks)\n",
      "Summary statistics for Cholesky factor:\n",
      "  Threads                   = 32\n",
      "  Rows in Factor            = 112\n",
      "  Integer space required    = 300\n",
      "  Total non-zeros in factor = 1543\n",
      "  Total FP ops to factor    = 26299\n",
      " Itn      Primal Obj        Dual Obj  Prim Inf Upper Inf  Dual Inf          \n",
      "   0   2.5856763e+05  -1.6950371e+06  1.10e+04  4.88e+01  2.26e+05\n",
      "   1   6.3662072e+04  -5.0908403e+05  2.95e+03  1.30e+01  6.03e+04\n",
      "   2   2.0825232e+04  -1.8555612e+05  3.84e+02  1.70e+00  7.86e+03\n",
      "   3   7.0661208e+03  -4.5533993e+04  2.70e+01  1.20e-01  5.53e+02\n",
      "   4   4.0648053e+03  -6.8828473e+03  5.18e+00  2.29e-02  1.06e+02\n",
      "   5   2.7622872e+03  -1.3647947e+03  1.12e+00  4.94e-03  2.29e+01\n",
      "   6   1.9030232e+03   2.9103638e+02  2.77e-01  1.23e-03  5.72e+00\n",
      "   7   1.3796230e+03   9.3585181e+02  3.68e-02  1.63e-04  7.60e-01\n",
      "   8   1.1771386e+03   1.1390333e+03  2.49e-11  7.46e-14  1.37e-12\n",
      "   9   1.1576416e+03   1.1525337e+03  1.65e-11  7.82e-14  7.13e-13\n",
      "  10   1.1561062e+03   1.1539774e+03  8.84e-11  8.53e-14  5.90e-13\n",
      "  11   1.1549755e+03   1.1549372e+03  4.98e-11  7.11e-14  1.58e-12\n",
      "  12   1.1549596e+03   1.1549520e+03  2.71e-09  7.11e-14  5.38e-13\n",
      "  13   1.1549559e+03   1.1549557e+03  5.06e-09  9.95e-14  1.15e-12\n",
      "  14   1.1549558e+03   1.1549558e+03  2.39e-09  4.26e-14  1.74e-12\n",
      "Barrier time = 0.02 sec. (1.01 ticks)\n",
      "\n",
      "Total time on 32 threads = 0.02 sec. (1.01 ticks)\n",
      "\n",
      "Barrier - Optimal:  Objective =  1.1549558097e+03\n",
      "Solution time =    0.02 sec.  Iterations = 14\n",
      "Deterministic time = 1.01 ticks  (67.58 ticks/sec)\n",
      "\n",
      "CPLEX> Solution written to file 'C:\\Users\\hanbo\\AppData\\Local\\Temp\\tmpxczzf4_x.cplex.sol'.\n",
      "CPLEX> "
     ]
    }
   ],
   "source": [
    "system_data = SystemDataProcessor(gen_csv_path, storage_csv_path, demand_csv_path)\n",
    "pyomo_system_data = system_data.prepare_pyomo_data(\n",
    "    num_periods=num_periods,\n",
    "    num_scenarios=num_scenarios,\n",
    "    num_tiers=num_tiers\n",
    ")\n",
    "\n",
    "dafo_model = DAFOModel(\n",
    "    num_periods=num_periods,\n",
    "    num_scenarios=num_scenarios,\n",
    "    num_generators=num_generators,\n",
    "    num_tiers=num_tiers,\n",
    "    num_storage=num_storage\n",
    ")\n",
    "da_instance = dafo_model.create_instance(pyomo_system_data)\n",
    "\n",
    "opt = pyo.SolverFactory(solver_name, executable=solver_exec)\n",
    "result = opt.solve(da_instance, tee=solver_options.get(\"tee\", False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_da_outputs(i, pyomo_system_data):\n",
    "    # Create DataFrame for energy values\n",
    "    Energy = pd.DataFrame()\n",
    "    # Fix xDA access to handle time dimension\n",
    "    E_grid_data = {(g): sum(i.xDA[g,t].value for t in i.T) for g in i.G}\n",
    "    \n",
    "    # Store the energy values\n",
    "    Energy['en'] = [i.xDA[g,t].value for g in i.G for t in i.T]\n",
    "    \n",
    "    # Directly store values in dictionary\n",
    "    xDA_data = {(g,t): i.xDA[g,t].value for g in i.G for t in i.T}\n",
    "    \n",
    "    # Store reserve requirements\n",
    "    temp = {t: i.rgDA[t].value for t in i.T}\n",
    "    \n",
    "    # Calculate total cost and price\n",
    "    Total = pd.DataFrame()\n",
    "    # Calculate total cost across all time periods\n",
    "    Total.at['cost','DA'] = sum(sum(i.VC[g] * i.xDA[g,t].value for g in i.G) for t in i.T)\n",
    "    # Calculate total price from dual values\n",
    "    Total.at['price','DA'] = sum(i.dual[i.Con3[t]] for t in i.T)\n",
    "    \n",
    "    # Handle demand data\n",
    "    E_grid_data = {(R): v.value for (R), v in i.hdu.items()}\n",
    "    demand = pd.DataFrame.from_dict(E_grid_data, orient=\"index\", columns=[\"hdu\"])\n",
    "    E_grid_data = {(R): v.value for (R), v in i.hdd.items()}\n",
    "    demand['hdd'] = pd.DataFrame.from_dict(E_grid_data, orient=\"index\", columns=[\"hdd\"])\n",
    "        \n",
    "    # Handle two-dimensional variables hsu and hsd\n",
    "    hsu_data = {}\n",
    "    hsd_data = {}\n",
    "    for r in i.R:\n",
    "        for g in i.G:\n",
    "            for t in i.T:\n",
    "                hsu_data[(r,g,t)] = i.hsu[r,g,t].value\n",
    "                hsd_data[(r,g,t)] = i.hsd[r,g,t].value\n",
    "\n",
    "    df = pd.DataFrame.from_dict(hsu_data, orient=\"index\", columns=[\"hsu\"])\n",
    "    df['hsd'] = pd.DataFrame.from_dict(hsd_data, orient=\"index\", columns=[\"hsd\"])\n",
    "    df['R'] = [k[0] for k in df.index]\n",
    "    df['G'] = [k[1] for k in df.index]\n",
    "    df['T'] = [k[2] for k in df.index]\n",
    "    \n",
    "    # Initialize empty lists to store prices\n",
    "    up_prices = []\n",
    "    down_prices = []\n",
    "\n",
    "    # Collect prices for each time period and reserve tier\n",
    "    for t in i.T:\n",
    "        for r in i.R:\n",
    "            up_prices.append(i.dual[i.Con4UP[r,t]])\n",
    "            down_prices.append(i.dual[i.Con4DN[r,t]])\n",
    "\n",
    "    # Create DataFrame with the collected prices\n",
    "    Prices = pd.DataFrame({\n",
    "        'up': up_prices,\n",
    "        'down': down_prices,\n",
    "        'T': [t for t in i.T for r in i.R],  # repeat each time period for each reserve tier\n",
    "        'R': [r for t in i.T for r in i.R]   # repeat reserve tiers for each time period\n",
    "    })\n",
    "    \n",
    "    # Calculate Gross Margins\n",
    "    Gross_margins = pd.DataFrame()\n",
    "    \n",
    "    # Calculate energy margins using reshaping to avoid broadcasting errors\n",
    "    # First create an array of VC values\n",
    "    vc_array = np.array([i.VC[g] for g in i.G])\n",
    "    \n",
    "    # Calculate price component\n",
    "    price_component = sum(i.dual[i.Con3[t]] for t in i.T)\n",
    "    \n",
    "    # Create energy arrays that are properly shaped\n",
    "    energy_values = []\n",
    "    for g in i.G:\n",
    "        total_energy = sum(i.xDA[g,t].value for t in i.T)\n",
    "        energy_values.append(total_energy)\n",
    "    \n",
    "    # Now calculate the margins\n",
    "    Gross_margins[\"en\"] = (price_component - vc_array) * np.array(energy_values)\n",
    "    \n",
    "    # Calculate reserve margins for each tier\n",
    "    for tier in range(1,5):\n",
    "        # Filter for specific tier and time period\n",
    "        tier_data = df[df[\"R\"]==tier]\n",
    "        \n",
    "        # If you have multiple time periods, you might want to aggregate or select a specific one\n",
    "        # For example, to get first time period:\n",
    "        tier_data = tier_data[tier_data[\"T\"]==1].reset_index(drop=True)\n",
    "        \n",
    "        # Now calculate the margins\n",
    "        vcup_array = np.array([i.VCUP[k] for k in i.G])\n",
    "        price_component = Prices.at[tier-1,\"up\"] - np.multiply(vcup_array, i.probTU[tier])\n",
    "        temp2 = np.multiply(tier_data[\"hsu\"], price_component)\n",
    "        \n",
    "        temp2.index = range(1,6)\n",
    "        Gross_margins[\"up\"+str(tier)] = temp2\n",
    "    \n",
    "    # Extract storage decisions from DA stage\n",
    "    p_ch_DA_data = {(b,t): i.p_ch[b,t].value for b in i.B for t in i.T}\n",
    "    p_dch_DA_data = {(b,t): i.p_dch[b,t].value for b in i.B for t in i.T}\n",
    "\n",
    "    dataRT = {None:{\n",
    "        'RE': pyomo_system_data[None][\"RE\"],\n",
    "        'CAP': pyomo_system_data[None][\"CAP\"],\n",
    "        'VC': pyomo_system_data[None][\"VC\"],\n",
    "        'VCUP': pyomo_system_data[None][\"VCUP\"],\n",
    "        'VCDN': pyomo_system_data[None][\"VCDN\"],\n",
    "        'DEMAND': pyomo_system_data[None][\"DEMAND\"],\n",
    "        'D1': pyomo_system_data[None][\"D1\"],\n",
    "        'D2': pyomo_system_data[None][\"D2\"],\n",
    "        # 'prob':{1: 0.2},\n",
    "        # probability of each scenario\n",
    "        'prob':{1: 0.2, 2:0.2, 3:0.2, 4:0.2, 5:0.2},\n",
    "        'RR': pyomo_system_data[None][\"RR\"],\n",
    "        'xDA':xDA_data,\n",
    "        'PEN':pyomo_system_data[None][\"PEN\"],\n",
    "        'PENDN':pyomo_system_data[None][\"PENDN\"],\n",
    "        'REDA': temp,  # Changed from nested structure to direct assignment\n",
    "        'DAdr': {t: i.d[t].value for t in i.T},\n",
    "\n",
    "        # storage parameters\n",
    "        'E_MAX': pyomo_system_data[None][\"E_MAX\"],\n",
    "        'P_MAX': pyomo_system_data[None][\"P_MAX\"],\n",
    "        'ETA_CH': pyomo_system_data[None][\"ETA_CH\"],\n",
    "        'ETA_DCH': pyomo_system_data[None][\"ETA_DCH\"],\n",
    "        'STORAGE_COST': pyomo_system_data[None][\"STORAGE_COST\"],\n",
    "        'E0': pyomo_system_data[None][\"E0\"],\n",
    "        'E_FINAL': pyomo_system_data[None][\"E_FINAL\"],\n",
    "\n",
    "        # storage decisions\n",
    "        'p_ch_DA': p_ch_DA_data,\n",
    "        'p_dch_DA': p_dch_DA_data\n",
    "    }}\n",
    "    \n",
    "    # Return additional data along with dataRT\n",
    "    return dataRT, Total, df, demand, Energy, Prices, Gross_margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Constructing component 'E_MAX' from data={1: 0} failed:\n",
      "        RuntimeError: Failed to set value for param=E_MAX, index=1, value=0.\n",
      "    \tsource error message=\"Index '1' is not valid for indexed component\n",
      "    \t'E_MAX'\"\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to set value for param=E_MAX, index=1, value=0.\n\tsource error message=\"Index '1' is not valid for indexed component 'E_MAX'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\hanbo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyomo\\core\\base\\param.py:866\u001b[0m, in \u001b[0;36mParam.construct\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m data_items:\n\u001b[1;32m--> 866\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_when_not_present(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m, val)\n\u001b[0;32m    867\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\hanbo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyomo\\core\\base\\indexed_component.py:870\u001b[0m, in \u001b[0;36mIndexedComponent._validate_index\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;66;03m# Raise an exception\u001b[39;00m\n\u001b[0;32m    869\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m--> 870\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not valid for indexed component \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;241m%\u001b[39m (normalized_idx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m    873\u001b[0m )\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Index '1' is not valid for indexed component 'E_MAX'\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m dataRT, Total, df, demand, Energy, Prices, Gross_margins \u001b[38;5;241m=\u001b[39m _extract_da_outputs(da_instance, pyomo_system_data)\n\u001b[0;32m      3\u001b[0m dafo_model \u001b[38;5;241m=\u001b[39m RTSimModel(\n\u001b[0;32m      4\u001b[0m     num_periods\u001b[38;5;241m=\u001b[39mnum_periods,\n\u001b[0;32m      5\u001b[0m     num_scenarios\u001b[38;5;241m=\u001b[39mnum_scenarios, \n\u001b[0;32m      6\u001b[0m     num_generators\u001b[38;5;241m=\u001b[39mnum_generators,\n\u001b[0;32m      7\u001b[0m     num_storage\u001b[38;5;241m=\u001b[39mnum_storage\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m---> 10\u001b[0m iRT \u001b[38;5;241m=\u001b[39m \u001b[43mdafo_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataRT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m opt\u001b[38;5;241m.\u001b[39msolve(iRT)\n\u001b[0;32m     13\u001b[0m RTmargins \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n",
      "File \u001b[1;32mc:\\Users\\hanbo\\Documents\\Development\\Flexibility_Options\\src\\RTSimModel.py:229\u001b[0m, in \u001b[0;36mRTSimModel.create_instance\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_instance\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m--> 229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hanbo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyomo\\core\\base\\PyomoModel.py:734\u001b[0m, in \u001b[0;36mModel.create_instance\u001b[1;34m(self, filename, data, name, namespace, namespaces, profile_memory, report_timing, **kwds)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _namespaces:\n\u001b[0;32m    732\u001b[0m     _namespaces\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 734\u001b[0m \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_namespaces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprofile_memory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;66;03m# Indicate that the model is concrete/constructed\u001b[39;00m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    739\u001b[0m instance\u001b[38;5;241m.\u001b[39m_constructed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hanbo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyomo\\core\\base\\PyomoModel.py:771\u001b[0m, in \u001b[0;36mModel.load\u001b[1;34m(self, arg, namespaces, profile_memory)\u001b[0m\n\u001b[0;32m    769\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot load model model data from with object of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    770\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(arg)))\n\u001b[1;32m--> 771\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_model_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespaces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprofile_memory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hanbo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyomo\\core\\base\\PyomoModel.py:823\u001b[0m, in \u001b[0;36mModel._load_model_data\u001b[1;34m(self, modeldata, namespaces, **kwds)\u001b[0m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m component\u001b[38;5;241m.\u001b[39mctype \u001b[38;5;129;01mis\u001b[39;00m Model:\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_component\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodeldata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespaces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponent_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile_memory\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;66;03m# Note: As is, connectors are expanded when using command-line pyomo but not calling model.create(...) in a Python script.\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;66;03m# John says this has to do with extension points which are called from commandline but not when writing scripts.\u001b[39;00m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Uncommenting the next two lines switches this (command-line fails because it tries to expand connectors twice)\u001b[39;00m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;66;03m# connector_expander = ConnectorExpander()\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;66;03m# connector_expander.apply(instance=self)\u001b[39;00m\n\u001b[0;32m    833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile_memory \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pympler_available:\n",
      "File \u001b[1;32mc:\\Users\\hanbo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyomo\\core\\base\\PyomoModel.py:871\u001b[0m, in \u001b[0;36mModel._initialize_component\u001b[1;34m(self, modeldata, namespaces, component_name, profile_memory)\u001b[0m\n\u001b[0;32m    863\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConstructing \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m from data=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         declaration\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m         \u001b[38;5;28mstr\u001b[39m(data),\n\u001b[0;32m    869\u001b[0m     )\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 871\u001b[0m     \u001b[43mdeclaration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    873\u001b[0m     err \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\hanbo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyomo\\core\\base\\param.py:869\u001b[0m, in \u001b[0;36mParam.construct\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    868\u001b[0m     msg \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to set value for param=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, index=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, value=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124msource error message=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mstr\u001b[39m(key), \u001b[38;5;28mstr\u001b[39m(val), \u001b[38;5;28mstr\u001b[39m(msg))\n\u001b[0;32m    873\u001b[0m     )\n\u001b[0;32m    874\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# Flag that things are fully constructed now (and changing an\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# immutable Param is now an exception).\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to set value for param=E_MAX, index=1, value=0.\n\tsource error message=\"Index '1' is not valid for indexed component 'E_MAX'\""
     ]
    }
   ],
   "source": [
    "dataRT, Total, df, demand, Energy, Prices, Gross_margins = _extract_da_outputs(da_instance, pyomo_system_data)\n",
    "\n",
    "dafo_model = RTSimModel(\n",
    "    num_periods=num_periods,\n",
    "    num_scenarios=num_scenarios, \n",
    "    num_generators=num_generators,\n",
    "    num_storage=num_storage\n",
    ")\n",
    "\n",
    "iRT = dafo_model.create_instance(dataRT)\n",
    "opt.solve(iRT)\n",
    "\n",
    "RTmargins = pd.DataFrame()\n",
    "for s in iRT.S:\n",
    "    margins_for_scenario = []\n",
    "    for g in iRT.G:\n",
    "        gen_margin = 0\n",
    "        for t in iRT.T:\n",
    "            # Correct indexing for Con3 with both s and t\n",
    "            dual_value = iRT.dual[iRT.Con3[s, t]]\n",
    "            vc_component = iRT.prob[s] * dataRT[None][\"VC\"][g]\n",
    "            gen_adjustment = iRT.xup[s, g, t].value - iRT.xdn[s, g, t].value\n",
    "            \n",
    "            margin = (dual_value - vc_component) * gen_adjustment\n",
    "            gen_margin += margin\n",
    "            \n",
    "        margins_for_scenario.append(gen_margin)\n",
    "    \n",
    "    RTmargins[s] = margins_for_scenario\n",
    "    \n",
    "RTmargins.index = range(1, len(RTmargins) + 1)\n",
    "\n",
    "RTpayoffs = pd.DataFrame()\n",
    "for s in iRT.S: \n",
    "    if s < 5:\n",
    "        for t in iRT.T:\n",
    "            payoffs = []\n",
    "            for g in iRT.G:\n",
    "                mask = (df[\"R\"] >= s) & (df[\"G\"] == g)\n",
    "                hsu_sum_for_g = df.loc[mask, \"hsu\"].sum()\n",
    "                price_component = iRT.dual[iRT.Con3[s, t]] * hsu_sum_for_g\n",
    "                cost_component = iRT.prob[s] * dataRT[None][\"VCUP\"][g] * hsu_sum_for_g\n",
    "                payoff = -(price_component - cost_component)\n",
    "                payoffs.append(payoff)\n",
    "            \n",
    "            RTpayoffs[f\"UP{s}_t{t}\"] = payoffs\n",
    "            \n",
    "    if s > 1:\n",
    "        for t in iRT.T:\n",
    "            payoffs = []\n",
    "            for g in iRT.G:\n",
    "                mask = (df[\"R\"] < s) & (df[\"G\"] == g)\n",
    "                hsd_sum_for_g = df.loc[mask, \"hsd\"].sum()\n",
    "                price_component = iRT.dual[iRT.Con3[s, t]] * hsd_sum_for_g\n",
    "                cost_component = iRT.prob[s] * dataRT[None][\"VCDN\"][g] * hsd_sum_for_g\n",
    "                payoff = price_component - cost_component\n",
    "                payoffs.append(payoff)\n",
    "            \n",
    "            RTpayoffs[f\"DN{s}_t{t}\"] = payoffs\n",
    "\n",
    "RTpayoffs.index = range(1, len(RTpayoffs) + 1)\n",
    "\n",
    "Total = pd.DataFrame(index=['cost', 'price', 'unmet_demand'], \n",
    "                    columns=['DA'] + [f't{t}' for t in iRT.T])\n",
    "\n",
    "for s in iRT.S:\n",
    "    for t in iRT.T:\n",
    "        # Compute costs for each time period\n",
    "        up_costs = sum(dataRT[None][\"VCUP\"][g] * iRT.xup[s, g, t].value for g in iRT.G)\n",
    "        down_costs = sum(dataRT[None][\"VCDN\"][g] * (-iRT.xdn[s, g, t].value) for g in iRT.G)\n",
    "        \n",
    "        Total.at['cost', f't{t}'] = iRT.prob[s] * (up_costs + down_costs)\n",
    "        Total.at['price', f't{t}'] = iRT.dual[iRT.Con3[s, t]]\n",
    "        \n",
    "        # Unmet demand for each time period\n",
    "        d_value = iRT.d[s, t].value\n",
    "        D1_value = dataRT[None][\"D1\"][None]\n",
    "        D2_value = dataRT[None][\"D2\"][None]\n",
    "        Total.at['unmet_demand', f't{t}'] = iRT.prob[s] * (D1_value * d_value + D2_value * d_value * d_value)\n",
    "\n",
    "# Calculate price convergence for each time period\n",
    "price_convergence = pd.Series(index=iRT.T)\n",
    "for t in iRT.T:\n",
    "    price_convergence[t] = Total.at['price', 'DA'] - Total[f't{t}'].loc['price']\n",
    "\n",
    "# maintain time dimension\n",
    "premium_convergence = pd.DataFrame()\n",
    "for t in iRT.T:\n",
    "    premiums_t = (Gross_margins[Gross_margins.columns[Gross_margins.columns.str.startswith('up')]].sum().sum() +\n",
    "                 Gross_margins[Gross_margins.columns[Gross_margins.columns.str.startswith('down')]].sum().sum())\n",
    "    \n",
    "    premium_convergence[f'UP_t{t}'] = (Gross_margins[Gross_margins.columns[Gross_margins.columns.str.startswith('up')]].sum(axis=1) +\n",
    "                                      RTpayoffs[RTpayoffs.columns[RTpayoffs.columns.str.endswith(f'_t{t}')]].sum(axis=1))\n",
    "    \n",
    "    premium_convergence[f'DN_t{t}'] = (Gross_margins[Gross_margins.columns[Gross_margins.columns.str.startswith('down')]].sum(axis=1) +\n",
    "                                      RTpayoffs[RTpayoffs.columns[RTpayoffs.columns.str.endswith(f'_t{t}')]].sum(axis=1))\n",
    "\n",
    "premium_convergence.index.name = 'Generator'\n",
    "premium_convergence.index = premium_convergence.index + 1\n",
    "\n",
    "Total_margin = pd.DataFrame()\n",
    "for k in range(1, 1):\n",
    "    for t in iRT.T:\n",
    "        # Basic generator margins for each time period\n",
    "        Total_margin[f'gen_t{t}'] = (iRT.prob[k] * Gross_margins.sum(axis=1) + \n",
    "                                    RTmargins[k] + \n",
    "                                    RTpayoffs[RTpayoffs.columns[RTpayoffs.columns.str.endswith(f'_t{t}')]].sum(axis=1))\n",
    "        \n",
    "        # Renewable energy margins for each time period\n",
    "        re_adjustments = iRT.rgup[k, t].value - iRT.rgdn[k, t].value\n",
    "        dual_value = iRT.dual[iRT.Con3[k, t]]\n",
    "        da_dual_value = Total.at['price', 'DA']\n",
    "        \n",
    "        Total_margin.at['RE', f't{t}'] = (dual_value * re_adjustments +\n",
    "                                         iRT.prob[k] * dataRT[None][\"REDA\"][t] * da_dual_value - \n",
    "                                         iRT.prob[k] * premiums)\n",
    "        \n",
    "        # Demand response margins for each time period\n",
    "        d_value_rt = iRT.d[k, t].value\n",
    "        d_value_da = dataRT[None][\"DAdr\"][t]\n",
    "        D1_value = dataRT[None][\"D1\"][None]\n",
    "        D2_value = dataRT[None][\"D2\"][None]\n",
    "        \n",
    "        Total_margin.at['DR', f't{t}'] = (dual_value * d_value_rt + \n",
    "                                         iRT.prob[k] * d_value_da * da_dual_value -\n",
    "                                         iRT.prob[k] * (D1_value * (d_value_rt + d_value_da)) -\n",
    "                                         iRT.prob[k] * (D2_value * (d_value_rt + d_value_da) * (d_value_rt + d_value_da)))\n",
    "\n",
    "# Display results\n",
    "print(\"\\nRT Margins:\")\n",
    "print(round(RTmargins, 2))\n",
    "\n",
    "print(\"\\nRT Payoffs:\")\n",
    "print(round(RTpayoffs, 2))\n",
    "\n",
    "print(\"\\nSystem Metrics:\")\n",
    "print(round(Total, 2))\n",
    "\n",
    "print(\"\\nPremium Convergence:\")\n",
    "print(round(premium_convergence, 2))\n",
    "\n",
    "print(\"\\nTotal Margins:\")\n",
    "print(round(Total_margin, 2))\n",
    "\n",
    "print(\"\\nFO Supply AWARDS:\")\n",
    "print(round(df, 2))\n",
    "\n",
    "print(\"\\nFO Demand AWARDS:\")\n",
    "print(round(demand, 2))\n",
    "\n",
    "print(\"\\nDA Energy:\")\n",
    "print(round(Energy, 2))\n",
    "\n",
    "print(\"\\nPrices:\")\n",
    "print(round(Prices, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
